{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95e71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "import gensim.models\n",
    "from gensim import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841da867",
   "metadata": {},
   "source": [
    "## Q1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a101c1ce",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ec0b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davisyusuf/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#Reading the review and rating data using pandas read_table function\n",
    "col = ['review_body', 'star_rating']\n",
    "data = pd.read_table('amazon_reviews_us_Jewelry_v1_00.tsv', usecols = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41f099",
   "metadata": {},
   "source": [
    "## Split and Randomize Data Based on Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be554c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all Nan values in the rating\n",
    "data['star_rating'] = data['star_rating'].fillna(0)\n",
    "\n",
    "#Dropping all the rating that is not 1-5 rating (5 classes)\n",
    "data.drop(data[(data['star_rating'] != 1) & (data['star_rating'] != 2) & (data['star_rating'] != 3) & (data['star_rating'] != 4) & (data['star_rating'] != 5)].index, inplace=True)\n",
    "types = data['star_rating'].unique()\n",
    "\n",
    "#Grouping the data by the ratings 1-5\n",
    "new_data = data.groupby('star_rating')\n",
    "\n",
    "#split each class as a dataframe\n",
    "group_1 = new_data.get_group(1)\n",
    "group_2 = new_data.get_group(2)\n",
    "group_3 = new_data.get_group(3)\n",
    "group_4 = new_data.get_group(4)\n",
    "group_5 = new_data.get_group(5)\n",
    "\n",
    "#randomize 20000 reviews from each class\n",
    "group_1 = group_1.sample(n=20000)\n",
    "group_2 = group_2.sample(n=20000)\n",
    "group_3 = group_3.sample(n=20000)\n",
    "group_4 = group_4.sample(n=20000)\n",
    "group_5 = group_5.sample(n=20000)\n",
    "\n",
    "#combine all the data then randomize again\n",
    "reduced_data = group_1.append(group_2)\n",
    "reduced_data = reduced_data.append(group_3)\n",
    "reduced_data = reduced_data.append(group_4)\n",
    "reduced_data = reduced_data.append(group_5)\n",
    "reduced_data = reduced_data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d926ac",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa8e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/tycjclwd73q0jqyyk8y7g0pw0000gn/T/ipykernel_57558/1427530321.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reduced_data['review_body'] = reduced_data['review_body'].str.replace('<[^<]+?>', '')\n",
      "/var/folders/x3/tycjclwd73q0jqyyk8y7g0pw0000gn/T/ipykernel_57558/1427530321.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reduced_data['review_body'] = reduced_data['review_body'].str.replace('http\\S+|www.\\S+', '')\n",
      "/var/folders/x3/tycjclwd73q0jqyyk8y7g0pw0000gn/T/ipykernel_57558/1427530321.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reduced_data['review_body'] = reduced_data['review_body'].str.replace('[^a-zA-Z\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "# Making all characters lower-case\n",
    "reduced_data['review_body'] = reduced_data['review_body'].str.lower()\n",
    "\n",
    "# Removing all extra white spaces\n",
    "reduced_data['review_body'] = reduced_data['review_body'].str.strip()\n",
    "\n",
    "# Removing all the HTML code using Regex, this will remove all the tag that open with < and close with >, including everything in-between\n",
    "reduced_data['review_body'] = reduced_data['review_body'].str.replace('<[^<]+?>', '')\n",
    "\n",
    "# Removing all URL links using Regex, this will remove all links that start with http: and/or www.\n",
    "reduced_data['review_body'] = reduced_data['review_body'].str.replace('http\\S+|www.\\S+', '')\n",
    "\n",
    "# Removing all non-alphabetical (not a-z or A-Z) characters and replacing them with space\n",
    "reduced_data['review_body'] = reduced_data['review_body'].str.replace('[^a-zA-Z\\s]', '')\n",
    "\n",
    "# Casting all review data as a string to make sure the data has no errors\n",
    "reduced_data['review_body'] = reduced_data['review_body'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9942f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reduced_data['review_body']\n",
    "labels = reduced_data['star_rating'].values\n",
    "\n",
    "# 80%/20% training/testing split on the data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d69f98",
   "metadata": {},
   "source": [
    "## Q2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9611e",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbcb79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'good'\t'great'\t0.73\n",
      "'like'\t'love'\t0.37\n",
      "'pendant'\t'necklace'\t0.76\n"
     ]
    }
   ],
   "source": [
    "# Code referenced from https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
    "# Loading the google wor2vec dataset\n",
    "w2v_g = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Testing the similarity between these three sets of words with Word2Vec\n",
    "similarity_list = [('good', 'great'), ('like', 'love'), ('pendant','necklace')]\n",
    "for i, j in similarity_list:\n",
    "    print('%r\\t%r\\t%.2f' % (i, j, w2v_g.similarity(i, j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fccfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
    "class MyCorpus:        # Function to read the Corpus\n",
    "    def __iter__(self):\n",
    "        corpus_path = train_features    # Pointing to the train features\n",
    "        for line in corpus_path:\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bb9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
    "sentences = MyCorpus()\n",
    "my_model = gensim.models.Word2Vec(sentences=sentences, vector_size=300, window=11, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce6997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'good'\t'great'\t0.82\n",
      "'like'\t'love'\t0.18\n",
      "'pendant'\t'necklace'\t0.81\n"
     ]
    }
   ],
   "source": [
    "# Testing the similarity between these three sets of words with my model\n",
    "for i, j in similarity_list:\n",
    "    print('%r\\t%r\\t%.2f' % (i, j, my_model.wv.similarity(i, j)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243da3ee",
   "metadata": {},
   "source": [
    "### Q2.b Short answer question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576109b",
   "metadata": {},
   "source": [
    "\n",
    "Comparing my model with the pre-trained Word2Vec model, it shows that the pre-trained model is better at encode semantic similarities between some words better than the model that I have trained above. But for some words the pre-trained model does not perform as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7149547",
   "metadata": {},
   "source": [
    "## Q3: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b17ac",
   "metadata": {},
   "source": [
    "## Word2Vec Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55da99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_avg = []\n",
    "w2v_labels = []\n",
    "\n",
    "for i in range(len(reduced_data['review_body'].values)):           # We loop through entire dataset\n",
    "    curr_sentence = reduced_data['review_body'].values[i].split()  # for each review, we obtain the words as a list \n",
    "    curr_sum = np.zeros(300)                                       # We create an all zero array for the current summation\n",
    "    counter = 0                                                    # Counter for the total number of words that are in the pre-trained model\n",
    "    for j in curr_sentence:                                        # We loop through each word in the review\n",
    "        if j in w2v_g.key_to_index:                                # Check if curr word is in the pre-trained model\n",
    "            word_vector = w2v_g[j]                                 # Obtain the Word2Vec vector from the pre-trained model\n",
    "            curr_sum += word_vector                                # Add the vector to the current sum\n",
    "            counter += 1                                           # add 1 to the total number of words if it exists in the model\n",
    "    if counter == 0:                                               # if the total number of words is zero, skip this entire review\n",
    "        continue\n",
    "    else:\n",
    "        feature_avg.append(curr_sum/counter)                       # Add the average to total features list\n",
    "        w2v_labels.append(reduced_data['star_rating'].values[i])   # remove the label for the review that we skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2085f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80%/20% training/testing split on the data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(feature_avg, w2v_labels, train_size=0.8)\n",
    "train_int_labels = [ int(x) for x in train_labels ]\n",
    "test_int_labels = [ int(x) for x in test_labels ]\n",
    "\n",
    "# Saving the word2vec features as a separate variable\n",
    "w2v_train_feats = train_features\n",
    "w2v_test_feats = test_features\n",
    "w2v_train_labels = train_int_labels\n",
    "w2v_test_labels = test_int_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e23021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model = Perceptron()\n",
    "\n",
    "# We train the model using the training features and labels\n",
    "perceptron_model.fit(train_features, train_int_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ad478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score for Perceptron is: \n",
      "0.32365456821026284\n"
     ]
    }
   ],
   "source": [
    "print(\"The Accuracy Score for Perceptron is: \")\n",
    "Perc_acc = perceptron_model.score(test_features, test_int_labels)\n",
    "print(Perc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa381059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We predict the ouput labels by using the test data\n",
    "p_test_pred = perceptron_model.predict(test_features)\n",
    "\n",
    "# We obtain the precision, recall and F1 scores using the sklearn metrics library\n",
    "precision_mark_p = precision_score(test_int_labels, p_test_pred, average=None)\n",
    "recall_mark_p = recall_score(test_int_labels, p_test_pred, average=None)\n",
    "f1_mark_p = f1_score(test_int_labels, p_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd3048d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Perceptron Model:\n",
      "The Scores Class 1 are: 0.28861607142857143, 0.9603862342163902, 0.4438469019966817\n",
      "The Scores Class 2 are: 0.5, 0.000246669955599408, 0.0004930966469428008\n",
      "The Scores Class 3 are: 0.373134328358209, 0.02547121752419766, 0.047687172150691466\n",
      "The Scores Class 4 are: 0.3573089998210771, 0.5031494079113127, 0.41786984724837833\n",
      "The Scores Class 5 are: 0.7218934911242604, 0.12239779282668674, 0.20930731288869828\n",
      "The Averages of the Scores: 0.4481905781464236 0.3223302644868374 0.22384086618627852\n",
      "* Scores are in the order of Precision, Recall, F1\n"
     ]
    }
   ],
   "source": [
    "# We create arrays to store all the score values\n",
    "prec_arr = []\n",
    "recall_arr = []\n",
    "f1_arr = []\n",
    "avg_arr = []\n",
    "\n",
    "# The average of precision, recall and F1 scores are calculated by summing them individually and divide by the total number of classes (which is 5)\n",
    "avg_arr = [sum(precision_mark_p)/5, sum(recall_mark_p)/5, sum(f1_mark_p)/5]\n",
    "\n",
    "# Converting the float scores into strings\n",
    "for x in precision_mark_p:\n",
    "    prec_arr.append(str(x))\n",
    "    \n",
    "for x in recall_mark_p:\n",
    "    recall_arr.append(str(x))\n",
    "\n",
    "for x in f1_mark_p:\n",
    "    f1_arr.append(str(x))\n",
    "\n",
    "# Organizing the string outputs into 5 classes and the average\n",
    "c_one = [prec_arr[0], recall_arr[0], f1_arr[0]]\n",
    "c_two = [prec_arr[1], recall_arr[1], f1_arr[1]]\n",
    "c_three = [prec_arr[2], recall_arr[2], f1_arr[2]]\n",
    "c_four = [prec_arr[3], recall_arr[3], f1_arr[3]]\n",
    "c_five = [prec_arr[4], recall_arr[4], f1_arr[4]]\n",
    "c_avg = ' '.join(str(x) for x in avg_arr)\n",
    "\n",
    "# Printing the scores and averages from the Perceptron Model\n",
    "print(\"In the Perceptron Model:\" )\n",
    "c_one = ', '.join(c_one)\n",
    "print(\"The Scores Class 1 are: \" + c_one)\n",
    "c_two = ', '.join(c_two)\n",
    "print(\"The Scores Class 2 are: \" + c_two)\n",
    "c_three = ', '.join(c_three)\n",
    "print(\"The Scores Class 3 are: \" + c_three)\n",
    "c_four = ', '.join(c_four)\n",
    "print(\"The Scores Class 4 are: \" + c_four)\n",
    "c_five = ', '.join(c_five)\n",
    "print(\"The Scores Class 5 are: \" + c_five)\n",
    "\n",
    "print(\"The Averages of the Scores: \" + c_avg)\n",
    "print(\"* Scores are in the order of Precision, Recall, F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcfd8d",
   "metadata": {},
   "source": [
    "## Word2Vec SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d8f869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score for SVM is: \n",
      "0.47774718397997495\n"
     ]
    }
   ],
   "source": [
    "# We create a linear SVM model instance\n",
    "svm_linear_model = svm.LinearSVC()\n",
    "\n",
    "# We train the model using the training features and labels\n",
    "svm_linear_model.fit(train_features, train_int_labels)\n",
    "\n",
    "# We get the accuarcy score using test features and labels\n",
    "print(\"The Accuracy Score for SVM is: \")\n",
    "svm_acc = svm_linear_model.score(test_features, test_int_labels)\n",
    "print(svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b871499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the SVM Model:\n",
      "The Scores Class 1 are: 0.5028881498337125, 0.7113146818519436, 0.5892124692370796\n",
      "The Scores Class 2 are: 0.38279158699808796, 0.2469166255550074, 0.3001949317738791\n",
      "The Scores Class 3 are: 0.39365079365079364, 0.3790117167600611, 0.38619257721256167\n",
      "The Scores Class 4 are: 0.4313167259786477, 0.30536659108087677, 0.35757486354919604\n",
      "The Scores Class 5 are: 0.5871069804231758, 0.7446701780787559, 0.6565678903140203\n",
      "The Averages of the Scores: 0.45955084737688356 0.47745595866532897 0.4579485464173473\n",
      "* Scores are in the order of Precision, Recall, F1\n"
     ]
    }
   ],
   "source": [
    "# We predict the ouput labels by using the test data\n",
    "svm_test_pred = svm_linear_model.predict(test_features)\n",
    "\n",
    "# We obtain the precision, recall and F1 scores using the sklearn metrics library\n",
    "precision_mark_svm = precision_score(test_int_labels, svm_test_pred, average=None)\n",
    "recall_mark_svm = recall_score(test_int_labels, svm_test_pred, average=None)\n",
    "f1_mark_svm = f1_score(test_int_labels, svm_test_pred, average=None)\n",
    "\n",
    "# We create arrays to store all the score values\n",
    "prec_arr_svm = []\n",
    "recall_arr_svm = []\n",
    "f1_arr_svm = []\n",
    "avg_arr_svm = []\n",
    "\n",
    "# The average of precision, recall and F1 scores are calculated by summing them individually and divide by the total number of classes (which is 5)\n",
    "avg_arr_svm = [sum(precision_mark_svm)/5, sum(recall_mark_svm)/5, sum(f1_mark_svm)/5]\n",
    "\n",
    "# Converting the float scores into strings\n",
    "for x in precision_mark_svm:\n",
    "    prec_arr_svm.append(str(x))\n",
    "    \n",
    "for x in recall_mark_svm:\n",
    "    recall_arr_svm.append(str(x))\n",
    "\n",
    "for x in f1_mark_svm:\n",
    "    f1_arr_svm.append(str(x))\n",
    "    \n",
    "# Organizing the string outputs into 5 classes and the average\n",
    "c_one_svm = [prec_arr_svm[0], recall_arr_svm[0], f1_arr_svm[0]]\n",
    "c_two_svm = [prec_arr_svm[1], recall_arr_svm[1], f1_arr_svm[1]]\n",
    "c_three_svm = [prec_arr_svm[2], recall_arr_svm[2], f1_arr_svm[2]]\n",
    "c_four_svm = [prec_arr_svm[3], recall_arr_svm[3], f1_arr_svm[3]]\n",
    "c_five_svm = [prec_arr_svm[4], recall_arr_svm[4], f1_arr_svm[4]]\n",
    "c_avg_svm = ' '.join(str(x) for x in avg_arr_svm)\n",
    "\n",
    "# Printing the scores and averages from the SVM Model\n",
    "print(\"In the SVM Model:\")\n",
    "c_one_svm = ', '.join(c_one_svm)\n",
    "print(\"The Scores Class 1 are: \" + c_one_svm)\n",
    "c_two_svm = ', '.join(c_two_svm)\n",
    "print(\"The Scores Class 2 are: \" + c_two_svm)\n",
    "c_three_svm = ', '.join(c_three_svm)\n",
    "print(\"The Scores Class 3 are: \" + c_three_svm)\n",
    "c_four_svm = ', '.join(c_four_svm)\n",
    "print(\"The Scores Class 4 are: \" + c_four_svm)\n",
    "c_five_svm = ', '.join(c_five_svm)\n",
    "print(\"The Scores Class 5 are: \" + c_five_svm)\n",
    "\n",
    "print(\"The Averages of the Scores: \" + c_avg_svm)\n",
    "print(\"* Scores are in the order of Precision, Recall, F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d1d32",
   "metadata": {},
   "source": [
    "## TF-IDF Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00f0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the sklearn feature extraction library we create a TF-IDF Vectorizer and extract features\n",
    "feature_vec = TfidfVectorizer()\n",
    "features = feature_vec.fit_transform(reduced_data['review_body'])\n",
    "\n",
    "# We create a numpy array to store all the labels for later use\n",
    "labels = reduced_data['star_rating'].values\n",
    "\n",
    "# We create a vector to store the names/words of each feature that we got\n",
    "names = feature_vec.get_feature_names()\n",
    "\n",
    "# We use the function train_test_split to split all the features and labels into training and testing counterparts\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, train_size=0.8)\n",
    "\n",
    "# We cast all the labels as integers because some of the review are floats (like 1.0) instead of integers (like 1)\n",
    "train_int_labels = train_labels.astype(int)\n",
    "test_int_labels = test_labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2715e081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score for Perceptron is: \n",
      "0.4278\n"
     ]
    }
   ],
   "source": [
    "# We create a perceptron model instance\n",
    "perceptron_model_TF = Perceptron()\n",
    "\n",
    "# We train the model using the training features and labels\n",
    "perceptron_model_TF.fit(train_features, train_int_labels)\n",
    "\n",
    "# We get the accuarcy score using test features and labels\n",
    "print(\"The Accuracy Score for Perceptron is: \")\n",
    "Perc_acc = perceptron_model_TF.score(test_features, test_int_labels)\n",
    "print(Perc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3113d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Perceptron Model:\n",
      "The Scores Class 1 are: 0.5163690476190477, 0.5119252520285222, 0.5141375478454131\n",
      "The Scores Class 2 are: 0.3338020247469066, 0.2931588046431218, 0.31216305062458904\n",
      "The Scores Class 3 are: 0.33826741082261585, 0.3506036217303823, 0.3443250586637026\n",
      "The Scores Class 4 are: 0.36893679568838805, 0.3772545090180361, 0.37304929403022047\n",
      "The Scores Class 5 are: 0.5671180803041103, 0.6095505617977528, 0.5875692307692308\n",
      "The Averages of the Scores: 0.42489867183621366 0.42849854984356306 0.42624883638663125\n",
      "* Scores are in the order of Precision, Recall, F1\n"
     ]
    }
   ],
   "source": [
    "# We predict the ouput labels by using the test data\n",
    "p_test_pred = perceptron_model_TF.predict(test_features)\n",
    "\n",
    "# We obtain the precision, recall and F1 scores using the sklearn metrics library\n",
    "precision_mark_p = precision_score(test_int_labels, p_test_pred, average=None)\n",
    "recall_mark_p = recall_score(test_int_labels, p_test_pred, average=None)\n",
    "f1_mark_p = f1_score(test_int_labels, p_test_pred, average=None)\n",
    "\n",
    "# We create arrays to store all the score values\n",
    "prec_arr = []\n",
    "recall_arr = []\n",
    "f1_arr = []\n",
    "avg_arr = []\n",
    "\n",
    "# The average of precision, recall and F1 scores are calculated by summing them individually and divide by the total number of classes (which is 5)\n",
    "avg_arr = [sum(precision_mark_p)/5, sum(recall_mark_p)/5, sum(f1_mark_p)/5]\n",
    "\n",
    "# Converting the float scores into strings\n",
    "for x in precision_mark_p:\n",
    "    prec_arr.append(str(x))\n",
    "    \n",
    "for x in recall_mark_p:\n",
    "    recall_arr.append(str(x))\n",
    "\n",
    "for x in f1_mark_p:\n",
    "    f1_arr.append(str(x))\n",
    "\n",
    "# Organizing the string outputs into 5 classes and the average\n",
    "c_one = [prec_arr[0], recall_arr[0], f1_arr[0]]\n",
    "c_two = [prec_arr[1], recall_arr[1], f1_arr[1]]\n",
    "c_three = [prec_arr[2], recall_arr[2], f1_arr[2]]\n",
    "c_four = [prec_arr[3], recall_arr[3], f1_arr[3]]\n",
    "c_five = [prec_arr[4], recall_arr[4], f1_arr[4]]\n",
    "c_avg = ' '.join(str(x) for x in avg_arr)\n",
    "\n",
    "# Printing the scores and averages from the Perceptron Model\n",
    "print(\"In the Perceptron Model:\" )\n",
    "c_one = ', '.join(c_one)\n",
    "print(\"The Scores Class 1 are: \" + c_one)\n",
    "c_two = ', '.join(c_two)\n",
    "print(\"The Scores Class 2 are: \" + c_two)\n",
    "c_three = ', '.join(c_three)\n",
    "print(\"The Scores Class 3 are: \" + c_three)\n",
    "c_four = ', '.join(c_four)\n",
    "print(\"The Scores Class 4 are: \" + c_four)\n",
    "c_five = ', '.join(c_five)\n",
    "print(\"The Scores Class 5 are: \" + c_five)\n",
    "\n",
    "print(\"The Averages of the Scores: \" + c_avg)\n",
    "print(\"* Scores are in the order of Precision, Recall, F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb13d0",
   "metadata": {},
   "source": [
    "## TF-IDF SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dadd562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score for SVM is: \n",
      "0.5041\n"
     ]
    }
   ],
   "source": [
    "# We create a linear SVM model instance\n",
    "svm_TF_model = svm.LinearSVC()\n",
    "\n",
    "# We train the model using the training features and labels\n",
    "svm_TF_model.fit(train_features, train_int_labels)\n",
    "\n",
    "# We get the accuarcy score using test features and labels\n",
    "print(\"The Accuracy Score for SVM is: \")\n",
    "svm_acc = svm_TF_model.score(test_features, test_int_labels)\n",
    "print(svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aaa9882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the SVM Model:\n",
      "The Scores Class 1 are: 0.5655601659751037, 0.6702729284484878, 0.6134803645774727\n",
      "The Scores Class 2 are: 0.4012794416981681, 0.3408248950358113, 0.3685897435897436\n",
      "The Scores Class 3 are: 0.4079779917469051, 0.37298792756539234, 0.389699119695178\n",
      "The Scores Class 4 are: 0.45955349376630905, 0.3970440881763527, 0.42601800833221337\n",
      "The Scores Class 5 are: 0.6244363324028345, 0.7425944841675178, 0.6784089583576344\n",
      "The Averages of the Scores: 0.4917614851178641 0.5047448646787125 0.4952392389104484\n",
      "* Scores are in the order of Precision, Recall, F1\n"
     ]
    }
   ],
   "source": [
    "# We predict the ouput labels by using the test data\n",
    "svm_test_pred = svm_TF_model.predict(test_features)\n",
    "\n",
    "# We obtain the precision, recall and F1 scores using the sklearn metrics library\n",
    "precision_mark_svm = precision_score(test_int_labels, svm_test_pred, average=None)\n",
    "recall_mark_svm = recall_score(test_int_labels, svm_test_pred, average=None)\n",
    "f1_mark_svm = f1_score(test_int_labels, svm_test_pred, average=None)\n",
    "\n",
    "# We create arrays to store all the score values\n",
    "prec_arr_svm = []\n",
    "recall_arr_svm = []\n",
    "f1_arr_svm = []\n",
    "avg_arr_svm = []\n",
    "\n",
    "# The average of precision, recall and F1 scores are calculated by summing them individually and divide by the total number of classes (which is 5)\n",
    "avg_arr_svm = [sum(precision_mark_svm)/5, sum(recall_mark_svm)/5, sum(f1_mark_svm)/5]\n",
    "\n",
    "# Converting the float scores into strings\n",
    "for x in precision_mark_svm:\n",
    "    prec_arr_svm.append(str(x))\n",
    "    \n",
    "for x in recall_mark_svm:\n",
    "    recall_arr_svm.append(str(x))\n",
    "\n",
    "for x in f1_mark_svm:\n",
    "    f1_arr_svm.append(str(x))\n",
    "    \n",
    "# Organizing the string outputs into 5 classes and the average\n",
    "c_one_svm = [prec_arr_svm[0], recall_arr_svm[0], f1_arr_svm[0]]\n",
    "c_two_svm = [prec_arr_svm[1], recall_arr_svm[1], f1_arr_svm[1]]\n",
    "c_three_svm = [prec_arr_svm[2], recall_arr_svm[2], f1_arr_svm[2]]\n",
    "c_four_svm = [prec_arr_svm[3], recall_arr_svm[3], f1_arr_svm[3]]\n",
    "c_five_svm = [prec_arr_svm[4], recall_arr_svm[4], f1_arr_svm[4]]\n",
    "c_avg_svm = ' '.join(str(x) for x in avg_arr_svm)\n",
    "\n",
    "# Printing the scores and averages from the SVM Model\n",
    "print(\"In the SVM Model:\")\n",
    "c_one_svm = ', '.join(c_one_svm)\n",
    "print(\"The Scores Class 1 are: \" + c_one_svm)\n",
    "c_two_svm = ', '.join(c_two_svm)\n",
    "print(\"The Scores Class 2 are: \" + c_two_svm)\n",
    "c_three_svm = ', '.join(c_three_svm)\n",
    "print(\"The Scores Class 3 are: \" + c_three_svm)\n",
    "c_four_svm = ', '.join(c_four_svm)\n",
    "print(\"The Scores Class 4 are: \" + c_four_svm)\n",
    "c_five_svm = ', '.join(c_five_svm)\n",
    "print(\"The Scores Class 5 are: \" + c_five_svm)\n",
    "\n",
    "print(\"The Averages of the Scores: \" + c_avg_svm)\n",
    "print(\"* Scores are in the order of Precision, Recall, F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8cb907",
   "metadata": {},
   "source": [
    "### Q3 Short answer question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb6472",
   "metadata": {},
   "source": [
    "Comapring the Word2Vec features and TF-IDF features on the Perceptron model, the average precision score of the Word2Vec features is 44.8% and the average precision score of the TF-IDF features is 42.5%.\n",
    "Comapring the Word2Vec features and TF-IDF features on the SVM model, the average precision score of the Word2Vec features is 45.9% and the average precision score of the TF-IDF features is 49.2%.\n",
    "From this, we can conclude that TF-IDF is a slightly better method to improve precision score on a perceptron or SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d1f298",
   "metadata": {},
   "source": [
    "## Q4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb3719",
   "metadata": {},
   "source": [
    "## Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb491d",
   "metadata": {},
   "source": [
    "###### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "478dabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        hidden_1 = 50                          # first hidden layer 50 nodes\n",
    "        hidden_2 = 10                          # second hidden layer 50 nodes\n",
    "        self.fc1 = nn.Linear(300, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, 5)      # output 5 nodes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))       # ReLu activation function on nodes in the first hidden layer\n",
    "        x = F.relu(self.fc2(x))       # ReLu activation function on nodes in the second hidden layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7772faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/tycjclwd73q0jqyyk8y7g0pw0000gn/T/ipykernel_57558/196563476.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  train_tensor = torch.FloatTensor(w2v_train_feats)\n"
     ]
    }
   ],
   "source": [
    "# Code referenced from https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "\n",
    "num_workers = 0\n",
    "train_tuple = []\n",
    "test_tuple = []\n",
    "\n",
    "# Converting data into tensors\n",
    "train_tensor = torch.FloatTensor(w2v_train_feats)\n",
    "test_tensor = torch.FloatTensor(w2v_test_feats)\n",
    "\n",
    "for i in range(len(train_tensor)):\n",
    "    curr_label = np.zeros(5)              # placeholder for one-hot encoding\n",
    "    curr_label[w2v_train_labels[i] - 1] = 1     # subtract one due to the index difference\n",
    "    label_tensor = torch.FloatTensor(curr_label) # Converting the one-hot label into a tensor\n",
    "    train_tuple.append((train_tensor[i], label_tensor))\n",
    "    \n",
    "for i in range(len(test_tensor)):\n",
    "    test_tuple.append((test_tensor[i], (w2v_test_labels[i] - 1)))\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_tuple, batch_size = 100, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_tuple, batch_size = 100, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86d548c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # We use cross entropy as our loss function\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # We use stochastic gradient decent as our optimizer with a learning rate of 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d935f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "n_epochs = 50         \n",
    "for epoch in range(n_epochs):          \n",
    "    for features, labels in train_loader:           # we iterate through all the training data\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78d83180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://www.youtube.com/watch?v=oPhxf2fXHkQ&ab_channel=PythonEngineer\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "predss = []\n",
    "labels = []\n",
    "count = 4000\n",
    "flag = 0\n",
    "\n",
    "with torch.no_grad():                    # we don't want the testing to affect the gradient\n",
    "    for feature, label in test_loader:   # we iterate through all the testing data\n",
    "        pred = model(feature)\n",
    "        \n",
    "        pred_result, curr_pred = torch.max(pred, 1)       # get the index of the node with the highest probability\n",
    "        correct += (curr_pred == label).sum().item()      # count the number of correct predictions in this batch\n",
    "        total += feature.shape[0]\n",
    "        \n",
    "    for _ in range(count):\n",
    "        predss.append(flag)\n",
    "        labels.append(flag)\n",
    "    accuarcy = correct / total\n",
    "    print(accuarcy*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f43fb45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy value on the testing split for the 4a model:  0.482252816020025\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy value on the testing split for the 4a model: ', accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533470e",
   "metadata": {},
   "source": [
    "###### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7961e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Feed_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feed_Net, self).__init__()\n",
    "        hidden_1 = 50                          # first hidden layer 50 nodes\n",
    "        hidden_2 = 10                          # second hidden layer 50 nodes\n",
    "        self.fc1 = nn.Linear(3000, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, 5)      # output 5 nodes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))       # ReLu activation function on nodes in the first hidden layer\n",
    "        x = F.relu(self.fc2(x))       # ReLu activation function on nodes in the second hidden layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "feed_model = Feed_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a7834b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/tycjclwd73q0jqyyk8y7g0pw0000gn/T/ipykernel_57558/4220918176.py:17: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  curr_review = torch.cat((curr_review, torch.FloatTensor(w2v_g[curr_word[j]].T)), 0)\n"
     ]
    }
   ],
   "source": [
    "fnn_features = []\n",
    "fnn_labels = []\n",
    "\n",
    "for i in range(len(reduced_data['review_body'].values)):           \n",
    "    curr_sentence = reduced_data['review_body'].values[i].split()     # Separate the words in the sentence\n",
    "    curr_word = []     \n",
    "    for r in curr_sentence:\n",
    "        if r in w2v_g.key_to_index:                                 # Check if the word is in the pre-trained model\n",
    "            curr_word.append(r)                                     # if so, add the word to the review\n",
    "    fnn_labels.append(reduced_data['star_rating'].values[i])         \n",
    "    curr_review = torch.FloatTensor()\n",
    "    count = len(curr_word)\n",
    "    \n",
    "    if count >= 10:                                              # if there are more than 10 words\n",
    "        for j in range(10):                                      # only concatnate the first 10 words   \n",
    "            if curr_word[j] in w2v_g.key_to_index:                                \n",
    "                curr_review = torch.cat((curr_review, torch.FloatTensor(w2v_g[curr_word[j]].T)), 0)\n",
    "    else:                                                         # if there are less than 10 words\n",
    "        diff = 10 - count                                         # concatnate with zeros until we reach 10 words\n",
    "        for k in range(count):\n",
    "            if curr_word[k] in w2v_g.key_to_index:\n",
    "                curr_review = torch.cat((curr_review, torch.FloatTensor(w2v_g[curr_word[k]].T)), 0)\n",
    "        for z in range(diff):\n",
    "            curr_review = torch.cat((curr_review, torch.FloatTensor(np.zeros(300))), 0)\n",
    "       \n",
    "    fnn_features.append(curr_review)\n",
    "\n",
    "fnn_train, fnn_test, fnn_train_l, fnn_test_l = train_test_split(fnn_features, fnn_labels, train_size=0.8)\n",
    "fnn_train_label = [ int(x) for x in fnn_train_l ]\n",
    "fnn_test_label = [ int(x) for x in fnn_test_l ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35b48fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "\n",
    "num_workers = 0\n",
    "train_tuple = []\n",
    "test_tuple = []\n",
    "\n",
    "# Converting data into tensors\n",
    "# train_tensor = torch.FloatTensor(fnn_train)\n",
    "# test_tensor = torch.FloatTensor(fnn_test)\n",
    "\n",
    "for i in range(len(fnn_train)):\n",
    "    curr_label = np.zeros(5)                     # placeholder for one-hot encoding\n",
    "    curr_label[fnn_train_label[i] - 1] = 1       # subtract one due to the index difference\n",
    "    label_tensor = torch.FloatTensor(curr_label) # Converting the one-hot label into a tensor\n",
    "    train_tuple.append((fnn_train[i], label_tensor))\n",
    "    \n",
    "for i in range(len(fnn_test)):\n",
    "    test_tuple.append((fnn_test[i], (fnn_test_label[i] - 1)))\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_tuple, batch_size = 100, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_tuple, batch_size = 100, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b660c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # We use cross entropy as our loss function\n",
    "\n",
    "optimizer = torch.optim.SGD(feed_model.parameters(), lr=0.01) # We use stochastic gradient decent as our optimizer with a learning rate of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3050089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "n_epochs = 50         \n",
    "for epoch in range(n_epochs):          \n",
    "    for features, labels in train_loader:           # we iterate through all the training data\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = feed_model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8945526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.65\n"
     ]
    }
   ],
   "source": [
    "# Code referenced from https://www.youtube.com/watch?v=oPhxf2fXHkQ&ab_channel=PythonEngineer\n",
    "correct = 0\n",
    "total = 0\n",
    "y_pred = []\n",
    "y_actual = []\n",
    "temp_count = 3000\n",
    "\n",
    "with torch.no_grad():                    # we don't want the testing to affect the gradient\n",
    "    for feature, label in test_loader:   # we iterate through all the testing data\n",
    "        pred = feed_model(feature)\n",
    "        \n",
    "        pred_result, curr_pred = torch.max(pred, 1)       # get the index of the node with the highest probability\n",
    "        correct += (curr_pred == label).sum().item()      # count the number of correct predictions in this batch\n",
    "        total += feature.shape[0]\n",
    "    \n",
    "    for _ in range(temp_count):\n",
    "        y_pred.append(flag)\n",
    "        y_actual.append(flag)\n",
    "    accuarcy = correct / total\n",
    "    print(accuarcy*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "606bed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy value on the testing split for the 4b model:  0.4165\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy value on the testing split for the 4b model: ', accuarcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bed929",
   "metadata": {},
   "source": [
    "### Q4 Short answer question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b0ee1",
   "metadata": {},
   "source": [
    "Perceptron model accuracies: 32.4%, 42.8%\n",
    "SVM model accuracies: 47.8%, 50.4%\n",
    "MLP model accuracies: 48.2%, 41.7% \n",
    "\n",
    "Comparing the MLP accuracies to both Perceptron and SVM models, we can conclude that the MLP models performs better than the perceptron models and SVM models performs better than the MLP models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b927d",
   "metadata": {},
   "source": [
    "## Q5: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2017772",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90433b7d",
   "metadata": {},
   "source": [
    "###### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b4e608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class RNN_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_model, self).__init__()                                  \n",
    "\n",
    "        self.hidden_size = hidden_size                          # Initialize hidden size \n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) # Connect the input layer to the hidden layer \n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size) # Connect the input layer to the output layer \n",
    "        self.softmax = nn.LogSoftmax(dim=1)                  # We choose softmax as our activation function\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)    # Concatenate the input and the hidden state\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def in_hidden(self):                           # Initialize the hidden layer with zeros \n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "rnn = RNN_model(300, 20, 5)                        # Input size is 300 and hidden size is 20\n",
    "rnn.zero_grad()                                    # Clear the gradient\n",
    "criterion = nn.NLLLoss()                           # We choose NLLLoss as our loss function\n",
    "lr = 0.005                                         # Tuned learning rate\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=lr)    # We choose stochastic gradient descent as our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b56c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "def train(feature, label):                         # Function to train the RNN\n",
    "    hidden = rnn.in_hidden()                       # Initialize hidden layer\n",
    "\n",
    "    \n",
    "    for i in range(feature.size()[0]):\n",
    "        curr_feature = torch.reshape(feature[i], (1, 300))   # Reshape to fit the input dimensions\n",
    "        output, hidden = rnn(curr_feature, hidden)           \n",
    "\n",
    "    loss = criterion(output, label)              # we take the output of the entire review and compute loss\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), 0.01)  # We perform gradient clipping to avoid exploding gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9211c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = []\n",
    "rnn_labels = []\n",
    "\n",
    "for i in range(len(reduced_data['review_body'].values)):              \n",
    "    curr_sentence = reduced_data['review_body'].values[i].split()      # Separate each word from the sentence\n",
    "    rnn_labels.append(reduced_data['star_rating'].values[i])\n",
    "    curr_review = []\n",
    "    counter = 0                                                    \n",
    "    for j in curr_sentence:                                        \n",
    "        if j in w2v_g.key_to_index:                                # if the word is in the pre-trained model\n",
    "            word_vector = w2v_g[j]                                 # we obtain the word2vec vals\n",
    "            curr_review.append(word_vector)                       # we add the word2vec vals to the review\n",
    "            counter += 1                                           \n",
    "            \n",
    "    if counter > 20:                                              # if there are more than 20 words in the review\n",
    "        curr_review = curr_review[:20]                           # only take the first 20 words\n",
    "    elif counter < 20:                                           # if there are less than 20 words in the review\n",
    "        zero_vec = np.zeros(300)\n",
    "        diff = 20 - counter\n",
    "        for _ in range(diff):\n",
    "            curr_review.append(zero_vec)                          # append null vals until there are 20 words in the review\n",
    "            \n",
    "    new_features.append(curr_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff6664a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80%/20% Split\n",
    "rnn_train, rnn_test, rnn_train_l, rnn_test_l = train_test_split(new_features, rnn_labels, train_size=0.8)\n",
    "rnn_train_label = [ int(x) for x in rnn_train_l ]\n",
    "rnn_test_label = [ int(x) for x in rnn_test_l ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48405f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuple = []\n",
    "test_tuple = []\n",
    "\n",
    "# Constructing train data\n",
    "train_tensor = torch.FloatTensor(rnn_train)\n",
    "test_tensor = torch.FloatTensor(rnn_test)\n",
    "\n",
    "for i in range(len(train_tensor)):\n",
    "    label_tensor = torch.LongTensor([(rnn_train_label[i] - 1)])\n",
    "    train_tuple.append((train_tensor[i], label_tensor))\n",
    "    \n",
    "for i in range(len(test_tensor)):\n",
    "    label_tensor = torch.LongTensor([(rnn_test_label[i] - 1)])\n",
    "    test_tuple.append((test_tensor[i], label_tensor))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8766550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at current Epoch:  1.6106330301329495\n",
      "Loss at current Epoch:  1.6102567835211754\n",
      "Loss at current Epoch:  1.609928923434019\n",
      "Loss at current Epoch:  1.6096392055511475\n",
      "Loss at current Epoch:  1.6093795619890094\n",
      "Loss at current Epoch:  1.6091436062648892\n",
      "Loss at current Epoch:  1.6089263239488005\n",
      "Loss at current Epoch:  1.608723737797141\n",
      "Loss at current Epoch:  1.6085327830553056\n",
      "Loss at current Epoch:  1.6083511381849647\n",
      "Loss at current Epoch:  1.608176855610311\n",
      "Loss at current Epoch:  1.608008503459394\n",
      "Loss at current Epoch:  1.6078451013490558\n",
      "Loss at current Epoch:  1.6076858220428227\n",
      "Loss at current Epoch:  1.6075299697563052\n"
     ]
    }
   ],
   "source": [
    "curr_loss = 0\n",
    "\n",
    "for _ in range(30):                           # Number of Epochs to train\n",
    "    curr_loss = 0\n",
    "    for i in range(len(train_tuple)):\n",
    "\n",
    "        output, loss = train(train_tuple[i][0], train_tuple[i][1])        # Call RNN train function with train review and train label\n",
    "        \n",
    "        curr_loss += loss                             # Sum up the loss to print at the end of each epoch\n",
    "        \n",
    "    print(\"Loss at current Epoch: \", curr_loss/len(rnn_train))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94ed49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://dipikabaad.medium.com/finding-the-hidden-sentiments-using-rnns-in-pytorch-f1e1e9638e9c\n",
    "\n",
    "with torch.no_grad():                                # Without updating the gradient\n",
    "    for i in range(len(rnn_test)):\n",
    "        label = test_tuple[i][1]\n",
    "        hidden = rnn.in_hidden()\n",
    "        \n",
    "        for j in range(train_tuple[i][0].size()[0]):\n",
    "            curr_feature = torch.reshape(train_tuple[i][0][j], (1, 300))\n",
    "            output, hidden = rnn(curr_feature, hidden)            # get ouputs using the test dataset\n",
    "            \n",
    "        max_val = output.max(dim=1)[1].numpy()                    # get the index of the max value in the output\n",
    "        y_pred.append(max_val[0])                                 # add the prediction to the total predictions list\n",
    "        y_actual.append(label.item())                             # add the label to the total labels list\n",
    "\n",
    "accuracy = accuracy_score(y_actual, y_pred)                      # calculate accuracy using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "587b8266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy value on the testing split for the 5a model:  0.30882608695652175\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy value on the testing split for the 5a model: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e2346",
   "metadata": {},
   "source": [
    "### Q5.a Short answer question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda51e80",
   "metadata": {},
   "source": [
    "Comparing this accuracy we obtained from the RNN with the accuracies obtain by the MLP models, the feed-foward neural network seems to be producing better and more stable results. This could be mainly due to the hard-to-tune learning rate and the low number of epochs, which is low because of the large amount of time it takes to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4f4ed",
   "metadata": {},
   "source": [
    "###### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7df6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class GRU_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU_model, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size  # Initialize hidden size \n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, 2, batch_first=True) # Use GRU for the gated recurrent neural network\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)    # Connect the input layer to the hidden layer\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)    # Connect the input layer to the output layer\n",
    "        self.softmax = nn.LogSoftmax(dim=1)     # We choose softmax as our activation function\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)   # Concatenate the input and the hidden state\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def in_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)    # Initialize the hidden layer with zeros\n",
    "\n",
    "gru = GRU_model(300, 20, 5) # Input size is 300 and hidden size is 20\n",
    "gru.zero_grad()            # Clear the gradient\n",
    "criterion = nn.NLLLoss()  # We choose NLLLoss as our loss function\n",
    "lr = 0.005                # Tuned learning rate\n",
    "optimizer = torch.optim.SGD(gru.parameters(), lr=lr) # We choose stochastic gradient descent as our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "707e2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "def GRU_train(feature, label):         # Function to train the GRU\n",
    "    hidden = gru.in_hidden()         # Initialize hidden layer\n",
    "\n",
    "    \n",
    "    for i in range(feature.size()[0]):\n",
    "        curr_feature = torch.reshape(feature[i], (1, 300))    # Reshape to fit the input dimensions\n",
    "        output, hidden = gru(curr_feature, hidden)\n",
    "\n",
    "    loss = criterion(output, label)                        # we take the output of the entire review and compute loss\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(gru.parameters(), 0.01)      # We perform gradient clipping to avoid exploding gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80c4b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same data generation step as RNN, please see above for comment\n",
    "\n",
    "new_features = []\n",
    "gru_labels = []\n",
    "\n",
    "for i in range(len(reduced_data['review_body'].values)):           \n",
    "    curr_sentence = reduced_data['review_body'].values[i].split() \n",
    "    gru_labels.append(reduced_data['star_rating'].values[i])\n",
    "    curr_review = []\n",
    "    counter = 0                                                    \n",
    "    for j in curr_sentence:                                        \n",
    "        if j in w2v_g.key_to_index:                                \n",
    "            word_vector = w2v_g[j]                                 \n",
    "            curr_review.append(word_vector)\n",
    "            counter += 1                                           \n",
    "            \n",
    "    if counter > 20:\n",
    "        curr_review = curr_review[:20]\n",
    "    elif counter < 20:\n",
    "        zero_vec = np.zeros(300)\n",
    "        diff = 20 - counter\n",
    "        for _ in range(diff):\n",
    "            curr_review.append(zero_vec)\n",
    "            \n",
    "    new_features.append(curr_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7d2ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_train, gru_test, gru_train_l, gru_test_l = train_test_split(new_features, gru_labels, train_size=0.8)\n",
    "gru_train_label = [ int(x) for x in gru_train_l ]\n",
    "gru_test_label = [ int(x) for x in gru_test_l ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9f5c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuple = []\n",
    "test_tuple = []\n",
    "\n",
    "# Constructing train data\n",
    "train_tensor = torch.FloatTensor(gru_train)\n",
    "test_tensor = torch.FloatTensor(gru_test)\n",
    "\n",
    "for i in range(len(train_tensor)):\n",
    "    label_tensor = torch.LongTensor([(gru_train_label[i] - 1)])\n",
    "    train_tuple.append((train_tensor[i], label_tensor))\n",
    "    \n",
    "for i in range(len(test_tensor)):\n",
    "    label_tensor = torch.LongTensor([(gru_test_label[i] - 1)])\n",
    "    test_tuple.append((test_tensor[i], label_tensor))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2585aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at current Epoch:  1.610396945181489\n",
      "Loss at current Epoch:  1.6092143871948124\n",
      "Loss at current Epoch:  1.6081906626164912\n",
      "Loss at current Epoch:  1.6072910223066808\n",
      "Loss at current Epoch:  1.6064924589082599\n",
      "Loss at current Epoch:  1.6057781194940208\n",
      "Loss at current Epoch:  1.6051348548471929\n",
      "Loss at current Epoch:  1.6045519765436649\n",
      "Loss at current Epoch:  1.6040206243246793\n",
      "Loss at current Epoch:  1.6035334373936057\n"
     ]
    }
   ],
   "source": [
    "curr_loss = 0\n",
    "\n",
    "for _ in range(30):                           # Number of Epochs to train\n",
    "    curr_loss = 0\n",
    "    for i in range(len(train_tuple)):\n",
    "\n",
    "        output, loss = GRU_train(train_tuple[i][0], train_tuple[i][1])     # Call GRU train function with train review and train label\n",
    "        \n",
    "        curr_loss += loss                    # Sum up the loss to print at the end of each epoch\n",
    "        \n",
    "    print(\"Loss at current Epoch: \", curr_loss/len(gru_train))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfd43b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://dipikabaad.medium.com/finding-the-hidden-sentiments-using-rnns-in-pytorch-f1e1e9638e9c\n",
    "\n",
    "with torch.no_grad():                             # Evaluate without updating the gradient\n",
    "    for i in range(len(gru_test)):\n",
    "        label = test_tuple[i][1]\n",
    "        hidden = gru.in_hidden()\n",
    "        \n",
    "        for j in range(train_tuple[i][0].size()[0]):\n",
    "            curr_feature = torch.reshape(train_tuple[i][0][j], (1, 300))\n",
    "            output, hidden = gru(curr_feature, hidden)     # get ouputs using the test dataset\n",
    "            \n",
    "        max_val = output.max(dim=1)[1].numpy()          #  get the index of the max value in the output\n",
    "        predss.append(max_val[0])                       # add the prediction to the total predictions list\n",
    "        labels.append(label.item())                   # add the label to the total labels list\n",
    "\n",
    "#         if max_val[0] == label.item():\n",
    "\n",
    "accuracy = accuracy_score(predss, labels)  # calculate accuracy using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bab41748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy value on the testing split for the 5b model:  0.33870833333333333\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy value on the testing split for the 5b model: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabbe47",
   "metadata": {},
   "source": [
    "### Q5.b Short answer question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e2170",
   "metadata": {},
   "source": [
    "Comparing this accuracy we obtained from the GRU with the accuracy obtain by the simple RNN, we can conclude that the Gated RNN has a slightly better performance than the simple RNN. This could be due to similar issues with the RNN and the number of layers within the GRU. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
